\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{f-li2013}
\citation{f-li2013}
\citation{kaewtrakulpong2002}
\citation{zivkovic2004}
\citation{sobral2014}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Video Object Segmentation}{16}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:vos}{{3}{16}{Video Object Segmentation}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Method}{16}{section.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Trimap Generation}{16}{subsection.3.1.1}}
\newlabel{method-tg}{{3.1.1}{16}{Trimap Generation}{subsection.3.1.1}{}}
\citation{suzuki1985}
\citation{sklansky1982}
\citation{f-li2013}
\citation{f-li2013}
\citation{li2010}
\citation{li2010}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Overview of the proposed video object segmentation method. The images are a frame from the dataset SegTrack v2\nobreakspace  {}\cite  {f-li2013}.}}{17}{figure.3.1}}
\newlabel{fig-overview}{{3.1}{17}{Overview of the proposed video object segmentation method. The images are a frame from the dataset SegTrack v2~\cite {f-li2013}}{figure.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Color Similarity Calculation}{17}{subsection.3.1.2}}
\newlabel{method-csc}{{3.1.2}{17}{Color Similarity Calculation}{subsection.3.1.2}{}}
\citation{li2010}
\citation{tao2012}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Trimap generation. (a) Original frame. (b) Background subtraction result. (c) Convex hull (red) and bounding box (white) of the blob. (d) Convex hull (red) and bounding box (white) after expansion. The images are a frame from the dataset SegTrack v2\nobreakspace  {}\cite  {f-li2013}.}}{18}{figure.3.2}}
\newlabel{fig-trimap}{{3.2}{18}{Trimap generation. (a) Original frame. (b) Background subtraction result. (c) Convex hull (red) and bounding box (white) of the blob. (d) Convex hull (red) and bounding box (white) after expansion. The images are a frame from the dataset SegTrack v2~\cite {f-li2013}}{figure.3.2}{}}
\newlabel{equ-rbf-ef}{{3.1}{18}{Color Similarity Calculation}{equation.3.1.1}{}}
\newlabel{equ-rbf}{{3.2}{18}{Color Similarity Calculation}{equation.3.1.2}{}}
\citation{tao2012}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces An example of computing color similarity with RBF. (a) The two strokes specifies pixels having similarity 1 (green) and 0 (red). (b) The resulting RBF is applied on every pixel.}}{19}{figure.3.3}}
\newlabel{fig-image-matting}{{3.3}{19}{An example of computing color similarity with RBF. (a) The two strokes specifies pixels having similarity 1 (green) and 0 (red). (b) The resulting RBF is applied on every pixel}{figure.3.3}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Input Image and Strokes}}}{19}{figure.3.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Output Image}}}{19}{figure.3.3}}
\newlabel{equ-ef}{{3.3}{19}{Color Similarity Calculation}{equation.3.1.3}{}}
\newlabel{equ-eb}{{3.4}{19}{Color Similarity Calculation}{equation.3.1.4}{}}
\citation{siva2014}
\citation{achanta2012}
\newlabel{equ-w}{{3.5}{20}{Color Similarity Calculation}{equation.3.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Foreground-background Labelling}{20}{subsection.3.1.3}}
\newlabel{method-fbl}{{3.1.3}{20}{Foreground-background Labelling}{subsection.3.1.3}{}}
\citation{boykov2004}
\citation{f-li2013}
\citation{sobral2014}
\citation{papazoglou2013}
\citation{zhang2013}
\citation{kaewtrakulpong2002}
\citation{zivkovic2004}
\citation{papazoglou2013}
\citation{zhang2013}
\citation{kaewtrakulpong2002}
\citation{zivkovic2004}
\newlabel{equ-mini}{{3.9}{21}{Foreground-background Labelling}{equation.3.1.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Evaluation}{21}{section.3.2}}
\newlabel{os-evaluation}{{3.2}{21}{Evaluation}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Dataset}{21}{subsection.3.2.1}}
\newlabel{os-dataset}{{3.2.1}{21}{Dataset}{subsection.3.2.1}{}}
\newlabel{equ-fm}{{3.10}{21}{Dataset}{equation.3.2.10}{}}
\citation{kaewtrakulpong2002}
\citation{zivkovic2004}
\citation{papazoglou2013}
\citation{zhang2013}
\citation{papazoglou2013}
\citation{papazoglou2013}
\citation{papazoglou2013}
\citation{papazoglou2013}
\citation{zhang2013}
\citation{zhang2013}
\citation{papazoglou2013}
\citation{zhang2013}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Results}{22}{subsection.3.2.2}}
\newlabel{os-results}{{3.2.2}{22}{Results}{subsection.3.2.2}{}}
\citation{papazoglou2013}
\citation{wang2015}
\citation{papazoglou2013}
\citation{wang2015}
\citation{papazoglou2013}
\citation{zhang2013}
\citation{kaewtrakulpong2002}
\citation{zhang2013}
\citation{papazoglou2013}
\citation{zhang2013}
\citation{wang2012}
\citation{Chen2015}
\citation{decombas2012}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Comparison with methods \cite  {papazoglou2013} and \cite  {wang2015} on four videos birdfall, frog, hummingbird and penguin. The results are measured by F-Measure.}}{23}{table.3.1}}
\newlabel{tab:table1}{{3.1}{23}{Comparison with methods \cite {papazoglou2013} and \cite {wang2015} on four videos birdfall, frog, hummingbird and penguin. The results are measured by F-Measure}{table.3.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces The execution time of the comparison methods on four the videos: Birdfall, frog, hummingbird and penguin (in seconds).}}{23}{table.3.2}}
\newlabel{tab:table2}{{3.2}{23}{The execution time of the comparison methods on four the videos: Birdfall, frog, hummingbird and penguin (in seconds)}{table.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Background subtraction masks vs. final masks. The first row demonstrates the original frames, the second row shows the masks generated by background subtraction methods, while the third row is the final masks produced by our method.}}{24}{figure.3.4}}
\newlabel{fig-bs-vs-mask}{{3.4}{24}{Background subtraction masks vs. final masks. The first row demonstrates the original frames, the second row shows the masks generated by background subtraction methods, while the third row is the final masks produced by our method}{figure.3.4}{}}
\newlabel{fig:sigma}{{3.5(a)}{24}{Subfigure 3 3.5(a)}{subfigure.3.5.1}{}}
\newlabel{sub@fig:sigma}{{(a)}{24}{Subfigure 3 3.5(a)\relax }{subfigure.3.5.1}{}}
\newlabel{fig:constraints}{{3.5(b)}{24}{Subfigure 3 3.5(b)}{subfigure.3.5.2}{}}
\newlabel{sub@fig:constraints}{{(b)}{24}{Subfigure 3 3.5(b)\relax }{subfigure.3.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Parameter Influence:\nobreakspace  {}\ref  {fig:sigma} $\sigma $ vs. F-Measure in color spaces RGB, Lab and YCrCb. \nobreakspace  {}\ref  {fig:constraints} Effect of the number of constraints on mask quality. We evaluated the quality of the produced masks using the average F-Measure of the frames with different values of $\sigma $ and number of constraints.}}{24}{figure.3.5}}
\newlabel{fig-params}{{3.5}{24}{Parameter Influence:~\ref {fig:sigma} $\sigma $ vs. F-Measure in color spaces RGB, Lab and YCrCb. ~\ref {fig:constraints} Effect of the number of constraints on mask quality. We evaluated the quality of the produced masks using the average F-Measure of the frames with different values of $\sigma $ and number of constraints}{figure.3.5}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{24}{figure.3.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{24}{figure.3.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Content-Aware Video Compression. (a) Original frame. (b) Mask generated with the video object segmentation method described above. (c) The object pixels covered by the mask. (d) The frame blurred with bilateral filter. (e) The merged frame.}}{25}{figure.3.6}}
\newlabel{fig-comp-wf}{{3.6}{25}{Content-Aware Video Compression. (a) Original frame. (b) Mask generated with the video object segmentation method described above. (c) The object pixels covered by the mask. (d) The frame blurred with bilateral filter. (e) The merged frame}{figure.3.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Content-Aware Video Compression}{25}{section.3.3}}
\newlabel{os-compression}{{3.3}{25}{Content-Aware Video Compression}{section.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Bitrate of Compressed Videos. The X-axis shows the various quantization parameters, while the Y-axis is the bitrate (Kbps) of the compressed videos. Green lines are the bitrate of the original video, red lines show the bitrate of the composite videos with slight blurring, and blue lines demonstrate the bitrate of the composition videos but with heavy blurring. (a) and (b) shows the results with different coding methods.}}{26}{figure.3.7}}
\newlabel{fig-comp-br}{{3.7}{26}{Bitrate of Compressed Videos. The X-axis shows the various quantization parameters, while the Y-axis is the bitrate (Kbps) of the compressed videos. Green lines are the bitrate of the original video, red lines show the bitrate of the composite videos with slight blurring, and blue lines demonstrate the bitrate of the composition videos but with heavy blurring. (a) and (b) shows the results with different coding methods}{figure.3.7}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Inter-coding}}}{26}{figure.3.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Intra-coding}}}{26}{figure.3.7}}
\@setckpt{parts/30-video-object-segmentation}{
\setcounter{page}{27}
\setcounter{equation}{10}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{1}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{3}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{7}
\setcounter{table}{2}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{parentequation}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{1}
\setcounter{bookmark@seq@number}{25}
\setcounter{section@level}{1}
}
