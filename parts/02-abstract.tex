% A B S T R A C T
% ---------------

\begin{center}\textbf{Abstract}\end{center}

In this thesis proposal, we aim to develop an Augmented Reality (AR) framework for training scenarios.
Compared with the existing augmented reality applications, our proposed framework has three advantages: 1) the proposed method acts as an interactive system between the trainer and the trainee, while the existing methods typically guide the trainee through a fixed series of steps; 2) the proposed method does not need markers to estimate the 3D structure of the models and the environment; 3) the proposed method is compatible with commercial equipments that have less powerful graphics capacity and various network conditions.

Three sub-goals constitute our final goal.
The first sub-goal is a video object segmentation algorithm.
We present a method for extracting foreground objects from video and its application in content-aware video compression. Our method uses trimaps inferred from background subtraction to represent the foreground-background relationship. The appearance of foreground and background are modeled with Radial Basis Functions initialized from the background substraction step. Finally, the algorithm Graph Cuts is used to compute a binary mask. Our method is fully automatic, fast, and does not make restrictive assumptions about object motions. In experiments on standard data sets, the proposed approach achieves comparable results to the state-of-the-art video object segmentation methods but our method is much faster. We also demonstrate an application of the proposed method to content-aware video compression.
With this algorithm, we are able to leverage an existing 3D object pose estimation algorithm to perform a markerless 3D structure estimation for the models and the environment in a training scenario.

Given the rapid evolution of mobile devices in terms of both hardware and software, most of recent AR applications target in mobile devices, such as mobile phones and AR glasses.
The second sub-goal is a hybrid remote rendering method optimized for mobile devices, which minimizes network bandwidth requirement and interaction latency. To incorporate it into the proposed framework that targets at training scenarios, the hybrid remote rendering method is also able to support multi-client cooperation.
Our approach is a client-server architecture and maintains two versions of models: low-fidelity models and high-fidelity models, where low and high fidelity models differ in the number of polygons and in rendering quality.
On the client side, the mobile device renders low-fidelity models that have less polygons, lower fidelity of textures and lower quality rendering effects. On the server side, the workstation renders high-fidelity models that have more polygons, higher fidelity of textures and higher quality rendering effects.
We also conducted a user study to identify the effects that the proposed method has on user object recognition and quality of experience.

Finally, the last sub-goal is to combine the former two sub-goals to develop an AR framework for training scenarios.
It acts as a bridge between the trainer and the trainee when they are in different geometrical locations and is able to leverage the recently emerged augmented reality glasses or mobile devices.
Client-server pattern is used in this system. There are two types of clients in our system: a) trainer, b) trainee.
Both of the trainer and the trainee use AR glasses or mobile devices to capture videos of the environment.
% wording: it should be markerless instead of marker-less
Then the videos captured are sent to the server that uses the proposed video object segmentation algorithm combined with a markerless 3D object pose estimation method to calculate the pose of all the objects of interest.
Moving objects are rendered and the frames are sent to the clients and overlaid on the real scenes, i.e. any objects moved by the trainer will be rendered and sent to the trainee, and, similarly, any objects moved by the trainee are rendered and sent to the trainer.
During this course, the remote trainer guide the trainee through the real time operations and collect their operations, then the trainer is able to give customized feedbacks to each trainee, which is how the learning actually takes place.

\cleardoublepage
%\newpage
