\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Two categories of augmented reality training scenarios according to which objects people interact with.}}{13}{figure.2.1}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Interact with real objects}}}{13}{figure.2.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Interact with virtual objects}}}{13}{figure.2.1}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Overview of the proposed video object segmentation method. The images are a frame from the dataset SegTrack v2\nobreakspace {}\cite {f-li2013}.}}{17}{figure.3.1}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Trimap generation. (a) Original frame. (b) Background subtraction result. (c) Convex hull (red) and bounding box (white) of the blob. (d) Convex hull (red) and bounding box (white) after expansion. The images are a frame from the dataset SegTrack v2\nobreakspace {}\cite {f-li2013}.}}{18}{figure.3.2}
\contentsline {figure}{\numberline {3.3}{\ignorespaces An example of computing color similarity with RBF. (a) The two strokes specifies pixels having similarity 1 (green) and 0 (red). (b) The resulting RBF is applied on every pixel.}}{19}{figure.3.3}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Input Image and Strokes}}}{19}{figure.3.3}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Output Image}}}{19}{figure.3.3}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Background subtraction masks vs. final masks. The first row demonstrates the original frames, the second row shows the masks generated by background subtraction methods, while the third row is the final masks produced by our method.}}{24}{figure.3.4}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Parameter Influence:\nobreakspace {}\ref {fig:sigma} $\sigma $ vs. F-Measure in color spaces RGB, Lab and YCrCb. \nobreakspace {}\ref {fig:constraints} Effect of the number of constraints on mask quality. We evaluated the quality of the produced masks using the average F-Measure of the frames with different values of $\sigma $ and number of constraints.}}{24}{figure.3.5}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{24}{figure.3.5}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{24}{figure.3.5}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Content-Aware Video Compression. (a) Original frame. (b) Mask generated with the video object segmentation method described above. (c) The object pixels covered by the mask. (d) The frame blurred with bilateral filter. (e) The merged frame.}}{25}{figure.3.6}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Bitrate of Compressed Videos. The X-axis shows the various quantization parameters, while the Y-axis is the bitrate (Kbps) of the compressed videos. Green lines are the bitrate of the original video, red lines show the bitrate of the composite videos with slight blurring, and blue lines demonstrate the bitrate of the composition videos but with heavy blurring. (a) and (b) shows the results with different coding methods.}}{26}{figure.3.7}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Inter-coding}}}{26}{figure.3.7}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Intra-coding}}}{26}{figure.3.7}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces System architecture}}{28}{figure.4.1}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Workflow of communication between the server and the clients}}{29}{figure.4.2}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Server-side Workflow}}{30}{figure.4.3}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Client-side Workflow}}{31}{figure.4.4}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Two-pass rendering}}{31}{figure.4.5}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Screenshot of the user study application.}}{34}{figure.4.6}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Training Scenario Part 1. This figure shows how the operations made by the trainer are rendered on the trainee side. The gears represent the components in the training scenario. The black gears denote the real components, while grey ones are their previous poses and the green gears demonstrate the virtual component rendered by the augmented reality devices. Moreover, the oblique gears represent the current pose after a translation and a rotation.}}{44}{figure.5.1}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Training Scenario Part 2. This figure shows how the operations made by the trainees are rendered on the trainer side. The gears represent the components in the training scenario. The black gears denote the real component, while grey ones are their previous poses and the green gears demonstrate the virtual component rendered by the augmented reality devices. The oblique gears represent the current pose after a translation and a rotation.}}{45}{figure.5.2}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Communication Schema}}{47}{figure.5.3}
\addvspace {10\p@ }
